
import fs from 'fs-extra';
import { getDocument } from 'pdfjs-dist/legacy/build/pdf.mjs';

export interface LawSegment {
  label: string;
  number: number;
  text: string;
  page_hint: number;
}

function normalizeLabel(input: string) {
  return input.replace(/\s+/g, ' ').trim();
}

function stripRtf(rtf: string): string {
  let text = rtf;
  text = text.replace(/\\u(-?\d+)\?/g, (_, code) => String.fromCharCode(Number(code)));
  text = text
    .replace(/\\par\b/g, '\n')
    .replace(/\\tab\b/g, '\t')
    .replace(/\\line\b/g, '\n');
  text = text.replace(/\\[a-z]+\d*/g, '');
  text = text.replace(/[{}]/g, '');
  return text;
}

export function normalizeTitle(input: string) {
  const map: Record<string, string> = {
    č: 'c', ć: 'c', ž: 'z', š: 's', đ: 'dj', Č: 'c', Ć: 'c', Ž: 'z', Š: 's', Đ: 'dj'
  };
  return input
    .replace(/[čćžšđČĆŽŠĐ]/g, (ch) => map[ch] || ch)
    .toLowerCase()
    .replace(/\s+/g, ' ')
    .trim();
}

export function normalizeText(input: string) {
  let out = input;
  out = stripRtf(out);
  // Normalize non-breaking spaces before anything else
  out = out.replace(/\u00A0/g, ' ');

  if (/[ÃÄÅ]/.test(out)) {
    try {
      // @ts-ignore
      out = decodeURIComponent(escape(out));
    } catch { }
  }
  try {
    out = out.normalize('NFC');
  } catch { }
  out = out.replace(/Č[\s\u00A0\u2000-\u200B\n]+lan/gi, 'Član');
  out = out.replace(/C[\s\u00A0\u2000-\u200B\n]+lan/gi, 'Clan');
  out = out.replace(/Č[\s\u00A0\u2000-\u200B\n]+l\./gi, 'Čl.');
  out = out.replace(/Ч[\s\u00A0\u2000-\u200B\n]+лан/gi, 'Члан');

  // Handle "Član \n 6" fragmentation
  out = out.replace(/(Član|Clan|Čl\.|Члан)\s*\n\s*(\d+)/gi, '$1 $2');

  // Final collapse of all whitespace (but preserve newlines for structure)
  // Replace multiple horizontal whitespaces with single space
  out = out.replace(/[ \t\u00A0\u2000-\u200B]{2,}/g, ' ');
  // Replace multiple newlines with single newline
  out = out.replace(/\n{2,}/g, '\n');
  // Ensure newline around headings if they are stuck
  // (Optional but helpful)

  return out;
}

const ARTICLE_RE = /(\b|\n)\s*((?:Č\s*lan|C\s*lan|Č\s*lanak|C\s*lanak|Č\s*l\.|C\s*l\.))\s*(\d{1,3})\s*[\.)\-:\u2013\u2014]?/i;

export function parseSegments(fullText: string, disableHeuristics = false): LawSegment[] {
  // Initial normalization
  fullText = normalizeText(fullText);

  const segments: LawSegment[] = [];

  // Regex definitions
  const wsClass = "[\\s\\u00A0\\u2000-\\u200B]";
  const lineStart = "(?:^|\\n)";
  const upperClass = '[A-ZČĆŠŽĐА-ЯЉЊЂЋЏ]';
  const headingTokens = '(?:Č\\s*lan|C\\s*lan|Č\\s*lanak|C\\s*lanak|Č\\s*l\\.|C\\s*l\\.|Ч\\s*лан|Ч\\s*л\\.)';

  const strictHeading = (n: number) => new RegExp(`${lineStart}${headingTokens}${wsClass}*${n}(?:\\.|-|:\\u2013|\\u2014)${wsClass}*`, 'i');
  const looseHeading = (n: number) => new RegExp(`${lineStart}${headingTokens}${wsClass}*${n}${wsClass}*(?:\\.|-|:\\u2013|\\u2014)`, 'i');
  const noDotHeading = (n: number) => new RegExp(`${lineStart}${headingTokens}${wsClass}*${n}(?!\\d)${wsClass}*`, 'i');

  const candidateNums: number[] = [];
  {
    const mAll: number[] = [];
    const reAll = new RegExp(`${headingTokens}${wsClass}*(\\d{1,3})(?:\\.|-|:\\u2013|\\u2014|${wsClass}|$)`, 'gi');
    let m: RegExpExecArray | null;
    while ((m = reAll.exec(fullText))) {
      const num = Number(m[1]);
      if (!Number.isNaN(num)) mAll.push(num);
    }
    const uniq = new Set<number>(mAll);
    candidateNums.push(...uniq);
  }

  const maxNum = candidateNums.length ? Math.max(...candidateNums) : 0;
  const matches: { idx: number; num: number; raw: string }[] = [];

  if (maxNum > 0) {
    for (let n = 1; n <= maxNum; n++) {
      let idx = fullText.search(strictHeading(n));
      let raw = '';
      if (idx < 0) idx = fullText.search(looseHeading(n));
      if (idx < 0) idx = fullText.search(noDotHeading(n));
      if (idx < 0) {
        const inlineHeading = new RegExp(`(?:^|${wsClass})${headingTokens}${wsClass}*${n}${wsClass}*(?=${upperClass})`, 'iu');
        idx = fullText.search(inlineHeading);
      }
      if (idx < 0) {
        const inlineNoDot = new RegExp(`${headingTokens}${wsClass}*${n}(?!\\d)${wsClass}*`, 'i');
        idx = fullText.search(inlineNoDot);
      }

      if (idx >= 0) {
        raw = fullText.slice(idx, Math.min(fullText.length, idx + 48));
        matches.push({ idx, num: n, raw });
      }
    }
    matches.sort((a, b) => a.idx - b.idx);
  } else {
    // Fallback
    const regex = new RegExp(ARTICLE_RE.source, 'gi');
    let m: RegExpExecArray | null;
    while ((m = regex.exec(fullText))) {
      const num = Number(m[3]);
      const raw = m[0];
      matches.push({ idx: m.index, num, raw });
    }
  }

  const seen = new Set<number>();
  
  // Track page positions
  // We assume markers like [[PAGE_N]] are present if generated by pdf.service.ts
  const pageMarkers: { page: number, idx: number }[] = [];
  const pageRegex = /\[\[PAGE_(\d+)\]\]/g;
  let pm: RegExpExecArray | null;
  while ((pm = pageRegex.exec(fullText))) {
      pageMarkers.push({ page: Number(pm[1]), idx: pm.index });
  }
  
  for (let i = 0; i < matches.length; i++) {
    const start = matches[i];
    const endIdx = i + 1 < matches.length ? matches[i + 1].idx : fullText.length;
    const isCyr = /Члан/i.test(start.raw);
    const labelBase = isCyr ? 'Члан' : 'Član';
    const label = normalizeLabel(`${labelBase} ${start.num}`);

    // Slice text
    const snippetRaw = fullText.slice(start.idx, Math.min(endIdx, start.idx + 15000)); // Increased limit for pasted text
    const snippet = normalizeText(snippetRaw.trim());

    // Determine page hint
    let page_hint = 1;
    if (pageMarkers.length > 0) {
        // Find the last page marker that appears before (or near) the start index
        // Since we injected markers, they are part of the text now.
        // The start.idx is an index into fullText.
        // We find the page marker with largest idx that is <= start.idx
        const relevantMarker = pageMarkers.filter(m => m.idx <= start.idx).pop();
        if (relevantMarker) {
            page_hint = relevantMarker.page;
        }
    }

    if (!seen.has(start.num)) {
      segments.push({ label, number: start.num, text: snippet, page_hint });
      seen.add(start.num);
    }
  }

  // Heuristics for missing numbers
  const hasCyrillic = /Члан/i.test(fullText);
  const labelBaseAll = hasCyrillic ? 'Члан' : 'Član';

  if (maxNum > 0 && !disableHeuristics) {
    const missing: number[] = [];
    for (let n = 1; n <= maxNum; n++) if (!seen.has(n)) missing.push(n);

    for (const n of missing) {
      const label = normalizeLabel(`${labelBaseAll} ${n}`);
      const anyHeading = new RegExp(`(?:Č\\s*lan|C\\s*lan|Č\\s*l\\.|C\\s*l\\.|Ч\\s*лан|Ч\\s*л\\.)${wsClass}*${n}`, 'i');
      const idx = fullText.search(anyHeading);
      const page_hint = 1;

      if (idx >= 0) {
        // If found but not caught by main loop (rare but possible)
        // We can try to extract a snippet, or just mark it as found via heuristic
        const snippetRaw = fullText.slice(idx, Math.min(fullText.length, idx + 2000));
        const text = normalizeText(snippetRaw.trim());
        segments.push({ label, number: n, text, page_hint });
      } else {
        // Not found at all
        // segments.push({ label, number: n, text: "Nije detektovan tekst.", page_hint });
      }
      seen.add(n);
    }
  }

  // Add Intro if empty or starts late
  if (segments.length === 0) {
    const snippet = normalizeText(fullText.slice(0, Math.min(fullText.length, 4000)).trim());
    segments.push({ label: 'Uvod', number: 0, text: snippet, page_hint: 1 });
  } else if (segments[0].number > 1) {
    // Check if there is text before the first segment
    const firstIdx = matches[0]?.idx || 0;
    if (firstIdx > 50) {
      const introText = normalizeText(fullText.slice(0, firstIdx).trim());
      if (introText.length > 20) {
        segments.unshift({ label: 'Uvod', number: 0, text: introText, page_hint: 1 });
      }
    }
  }

  return segments;
}

export async function parseSegmentsFromPdf(pdfPath: string): Promise<LawSegment[]> {
  try {
    const buf = await fs.readFile(pdfPath);
    const u8 = new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength);
    const loadingTask = getDocument({ data: u8 });
    const pdf = await loadingTask.promise;

    const pages: string[] = [];
    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i);
      const textContent: any = await page.getTextContent({ normalizeWhitespace: true, disableCombineTextItems: false } as any);
      let lastY = null as number | null;
      let lastX = null as number | null;
      let lastChar = '';
      let text = '';
      const items = [...textContent.items].sort((a: any, b: any) => {
        const ay = a.transform ? a.transform[5] : 0;
        const by = b.transform ? b.transform[5] : 0;
        if (Math.abs(ay - by) > 2) return by - ay; // Different line (Y is top-to-bottom in PDF, but usually transform[5] is bottom-up)
        const ax = a.transform ? a.transform[4] : 0;
        const bx = b.transform ? b.transform[4] : 0;
        return ax - bx; // Same line, sort left to right
      });

      for (const item of items) {
        const str = String(item.str || '');
        const y = item.transform ? item.transform[5] : null;
        const x = item.transform ? item.transform[4] : null;
        
        // Handle newlines based on Y position
        if (lastY !== null && y !== null && Math.abs(lastY - y) > 9) {
           text += '\n';
           lastX = null; // Reset X tracking on new line
        }
        
        // Handle horizontal spaces based on X position
        if (lastX !== null && x !== null) {
          const widthEstimate = (item.width || (str.length * 5)) / str.length; // rough char width if item.width missing
          // If the gap between previous end (lastX + previous width?) and current X is large, insert space
          // But we don't track previous width easily here without keeping previous item.
          // Using a simple heuristic: if difference is > 2 units (usually pixels/points), insert space
          // Note: item.transform[4] is the start X.
          // We ideally need the END X of the previous item.
          // But we only have lastX which is start of previous item.
          // Let's assume we rely on the heuristic from before:
          if (Math.abs(lastX - x) > 2) {
             // Logic was: if distance > 2, verify chars. 
             // But lastX is start of previous item. Distance (x - lastX) is distance between STARTS.
             // This is wrong for variable width text.
             // Correct logic: if (x - (prevX + prevWidth)) > threshold -> space.
             // Since we don't have easy prevWidth, let's just ensure we separate words if there's no space in string.
          }
        }
        
        // The original logic had issues with detecting spaces. 
        // Let's just concatenate with a space if it seems like separate words and not punctuation.
        // Actually, pdf.js textContent usually splits by spacing.
        // If we just join with space if it's not a newline, we might over-space.
        // But better over-space than under-space for search.
        // Let's rely on simple concat but check for alphanumeric boundary
        
        if (lastY !== null && y !== null && Math.abs(lastY - y) <= 9) {
            // Same line.
            // If the previous char was alphanumeric and this one is too, insert space.
            // (Unless it's a suffix/punctuation).
            // This is a heuristic.
            if (/\w$/.test(text) && /^\w/.test(str)) {
                text += ' '; 
            }
        }
        
        text += str;
        if (y !== null) lastY = y;
        if (x !== null) lastX = x;
        if (str.length) lastChar = str.charAt(str.length - 1);
      }
      const cleaned = text.replace(/\s+\n/g, '\n').replace(/\s{2,}/g, ' ').trim();
      const cleanedNorm = normalizeText(cleaned);
      pages.push(cleanedNorm);
    }
    await pdf.cleanup();

    const PAGE_SEP = '\n\n';
    const fullText = pages.join(PAGE_SEP);

    // Calculate page offsets
    const pageOffsets: number[] = [];
    let acc = 0;
    for (let i = 0; i < pages.length; i++) {
      pageOffsets.push(acc);
      acc += pages[i].length + PAGE_SEP.length;
    }

    const pageForIndex = (idx: number) => {
      let lo = 0, hi = pageOffsets.length - 1;
      while (lo <= hi) {
        const mid = (lo + hi) >> 1;
        const start = pageOffsets[mid];
        const nextStart = mid + 1 < pageOffsets.length ? pageOffsets[mid + 1] : Number.POSITIVE_INFINITY;
        if (idx >= start && idx < nextStart) return mid + 1;
        if (idx < start) hi = mid - 1;
        else lo = mid + 1;
      }
      return 1;
    };

    // Use the main parsing logic but now mapped to pages
    // Note: We're basically duplicating the logic from parseSegments but adding page_hint calculation
    // Ideally we'd refactor parseSegments to accept pageOffsets, but copying is safer for now to avoid breaking existing code

    const wsClass = "[\\s\\u00A0\\u2000-\\u200B]";
    const lineStart = "(?:^|\\n)";
    const upperClass = '[A-ZČĆŠŽĐА-ЯЉЊЂЋЏ]';
    const headingTokens = '(?:Č\\s*lan|C\\s*lan|Č\\s*lanak|C\\s*lanak|Č\\s*l\\.|C\\s*l\\.|Ч\\s*лан|Ч\\s*л\\.)';
    const strictHeading = (n: number) => new RegExp(`${lineStart}${headingTokens}${wsClass}*${n}(?:\\.|-|:\\u2013|\\u2014)${wsClass}*`, 'i');
    const looseHeading = (n: number) => new RegExp(`${lineStart}${headingTokens}${wsClass}*${n}${wsClass}*(?:\\.|-|:\\u2013|\\u2014)`, 'i');
    const noDotHeading = (n: number) => new RegExp(`${lineStart}${headingTokens}${wsClass}*${n}(?!\\d)${wsClass}*`, 'i');

    const candidateNums: number[] = [];
    {
      const mAll: number[] = [];
      const reAll = new RegExp(`${headingTokens}${wsClass}*(\\d{1,3})(?:\\.|-|:\\u2013|\\u2014|${wsClass}|$)`, 'gi');
      let m: RegExpExecArray | null;
      while ((m = reAll.exec(fullText))) {
        const num = Number(m[1]);
        if (!Number.isNaN(num)) mAll.push(num);
      }
      const uniq = new Set<number>(mAll);
      candidateNums.push(...uniq);
    }

    const maxNum = candidateNums.length ? Math.max(...candidateNums) : 0;
    const matches: { idx: number; num: number; raw: string }[] = [];

    if (maxNum > 0) {
      for (let n = 1; n <= maxNum; n++) {
        let idx = fullText.search(strictHeading(n));
        let raw = '';
        if (idx < 0) idx = fullText.search(looseHeading(n));
        if (idx < 0) idx = fullText.search(noDotHeading(n));
        if (idx < 0) {
          const inlineHeading = new RegExp(`(?:^|${wsClass})${headingTokens}${wsClass}*${n}${wsClass}*(?=${upperClass})`, 'iu');
          idx = fullText.search(inlineHeading);
        }
        if (idx < 0) {
          const inlineNoDot = new RegExp(`${headingTokens}${wsClass}*${n}(?!\\d)${wsClass}*`, 'i');
          idx = fullText.search(inlineNoDot);
        }

        if (idx >= 0) {
          raw = fullText.slice(idx, Math.min(fullText.length, idx + 48));
          matches.push({ idx, num: n, raw });
        }
      }
      matches.sort((a, b) => a.idx - b.idx);
    } else {
      const regex = new RegExp(ARTICLE_RE.source, 'gi');
      let m: RegExpExecArray | null;
      while ((m = regex.exec(fullText))) {
        const num = Number(m[3]);
        const raw = m[0];
        matches.push({ idx: m.index, num, raw });
      }
    }

    const segments: LawSegment[] = [];
    const seen = new Set<number>();

    for (let i = 0; i < matches.length; i++) {
      const start = matches[i];
      const endIdx = i + 1 < matches.length ? matches[i + 1].idx : fullText.length;
      const isCyr = /Члан/i.test(start.raw);
      const labelBase = isCyr ? 'Члан' : 'Član';
      const label = normalizeLabel(`${labelBase} ${start.num}`);
      const snippetRaw = fullText.slice(start.idx, Math.min(endIdx, start.idx + 15000));
      const snippet = normalizeText(snippetRaw.trim());
      const page_hint = pageForIndex(start.idx);

      if (!seen.has(start.num)) {
        segments.push({ label, number: start.num, text: snippet, page_hint });
        seen.add(start.num);
      }
    }

    // Heuristics for missing numbers
    const hasCyrillic = /Члан/i.test(fullText);
    const labelBaseAll = hasCyrillic ? 'Члан' : 'Član';

    if (maxNum > 0) {
      const missing: number[] = [];
      for (let n = 1; n <= maxNum; n++) if (!seen.has(n)) missing.push(n);

      for (const n of missing) {
        const label = normalizeLabel(`${labelBaseAll} ${n}`);
        const anyHeading = new RegExp(`(?:Č\\s*lan|C\\s*lan|Č\\s*l\\.|C\\s*l\\.|Ч\\s*лан|Ч\\s*л\\.)${wsClass}*${n}`, 'i');
        const idx = fullText.search(anyHeading);
        const page_hint = idx >= 0 ? pageForIndex(idx) : 1;

        if (idx >= 0) {
          const snippetRaw = fullText.slice(idx, Math.min(fullText.length, idx + 2000));
          const text = normalizeText(snippetRaw.trim());
          segments.push({ label, number: n, text, page_hint });
        }
        seen.add(n);
      }
    }

    // Intro
    if (segments.length === 0) {
      const snippet = normalizeText(fullText.slice(0, Math.min(fullText.length, 4000)).trim());
      segments.push({ label: 'Uvod', number: 0, text: snippet, page_hint: 1 });
    } else if (segments[0].number > 1) {
      const firstIdx = matches[0]?.idx || 0;
      if (firstIdx > 50) {
        const introText = normalizeText(fullText.slice(0, firstIdx).trim());
        if (introText.length > 20) {
          segments.unshift({ label: 'Uvod', number: 0, text: introText, page_hint: 1 });
        }
      }
    }

    return segments;

  } catch (e) {
    console.error('Failed to parse segments from PDF:', e);
    return [];
  }
}
